{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning</h1><h2 align=\"center\" style=\"margin:10px\">Assignment 3</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student names and numbers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignments below should be solved and documented as a mini-project that will form the basis for the\n",
    "examination. When solving the exercises it is important that you\n",
    "\n",
    "  * document all relevant results and analyses that you have obtained/performed during the exercises\n",
    "  * try to relate your results to the theoretical background of the methods being applied.\n",
    "\n",
    "Feel free to add cells if you need to. The easiest way to convert to pdf is to save this notebook as .html (File-->Download as-->HTML) and then convert this html file to pdf. You can also export as pdf directly, but here you need to watch your margins as the converter will cut off your code (i.e. make vertical code!).\n",
    "\n",
    "Last, but not least:\n",
    "* Looking for an overview of the markdown language? The cheat sheet <a href=\"https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\">here</a> might help.\n",
    "* For the Python specific components of the exercises, you should not need constructs beyond those that are already included in the notebooks on the course's web-page (still you should not feel constrained by these, so feel free to be adventurous). You may, however, need to consult the documentation for some of the methods supplied by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will be using the famous nycflights13 data which contains the `airlines`, `airports`, `flights`, `planes`, and `weather` datasets. Please see the documentation (`nycflights13.pdf`) for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Load all files as pandas dataframes and display the first 5 rows of each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Convert all temperature attributes to degree Celsius. We will be using this in what follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Using OLS, investigate if flight distance is associated with arrival delay. You should be cautious regarding negative delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Using OLS, investigate if departure delay is associated with arrival delay. Again,\n",
    "   consider what to do with negative delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Investigate whether departure delay is associated with weather conditions\n",
    "   at the origin airport. This includes descriptives, plotting, regression modelling,\n",
    "   considering missing values etc. For regression, do OLS, Ridge, Lasso, and Elastic Net.\n",
    "   The analysis should also include seasonality trends as a \"weather condition\". You could,\n",
    "   for instance, plot the daily departure delay with the date (or monthly). What are the\n",
    "   three most important weather conditions when trying to predict departure delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Is the age of the plane associated with delay? Do OLS, Ridge, Lasso, and Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** Do a principal component analysis of the weather at JFK using the following columns:\n",
    "   temp, dewp, humid, wind_dir, wind_speed, precip, visib.\n",
    "   How many principal components should be used to capture the variability in the weather data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h)** Build regression models (OLS, Ridge, Lasso, and Elastic Net) that associates\n",
    "   an airports lattitude with weather conditions (temp, dewp, humid, wind_dir, wind_speed,\n",
    "   precip, visib). Remove all but the three most significant whether conditions and redo\n",
    "   the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i)** On a map, plot the airports that have flights to them where the points that represent\n",
    "   airports are relative in size to the average departure delay. You can see an example in \"airports.png\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **j)** These questions require no code.\n",
    " - Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter or reduce it?\n",
    "\n",
    "- Why would you want to use:\n",
    "        > Ridge Regression instead of plain Linear Regression (i.e. without any regularization)?\n",
    "        > Lasso instead of Ridge Regression?\n",
    "        > Elastic Net instead of Lasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will depart from the equally famous mnist dataset. This is a \".mat\" file, in order to load this file in an ipynb you have to use loadmat() function from scipy.io. (replace my path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 70000\n",
      "\n",
      "Number of features: 784\n",
      "\n",
      "List of labels: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "mnist = loadmat('mnist-original')\n",
    "mnist_data = mnist[\"data\"].T\n",
    "mnist_label = mnist[\"label\"][0]\n",
    "import numpy as np\n",
    "print(\"Number of datapoints: {}\\n\".format(mnist_data.shape[0]))\n",
    "print(\"Number of features: {}\\n\".format(mnist_data.shape[1]))\n",
    "print(\"List of labels: {}\\n\".format(np.unique(mnist_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, and each image has 784 features. This is because each image is 28×28 pixels,\n",
    "and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black). Let’s take a peek at one digit from the dataset. All you need to do is grab an instance’s feature vector, reshape it to a 28×28 array, and display it using Matplotlib’s `imshow()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of datapoint no. 4:\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  46 105 254 254 254 254 255 239  41\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  37\n",
      " 118 222 254 253 253 253 253 253 253 211  54   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  14 200 253 253 254 253 253 253 253 253\n",
      " 253 253 116   0   0   0   0   0   0   0   0   0   0   0   0   0  16 160\n",
      " 236 253 253 253 254 253 253 246 229 253 253 253 116   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  99 253 253 253 253 253 254 253 253 213\n",
      "  99 253 253 253 116   0   0   0   0   0   0   0   0   0   0   0   0  25\n",
      " 194 253 253 253 253 131  97 169 253  93  99 253 253 253 116   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 206 253 253 251 233 127   9   0  18\n",
      "  38   3  15 171 253 253 116   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 240 253 253 233   0   0   0   0   0   0   0  31 186 253 253 116   0\n",
      "   0   0   0   0   0   0   0   0   0   0 176 253 253 253 127   0   0   0\n",
      "   0   0   0   0  99 253 253 253 116   0   0   0   0   0   0   0   0   0\n",
      "   0   0 176 253 253 131   9   0   0   0   0   0   0   0  99 253 253 253\n",
      " 116   0   0   0   0   0   0   0   0   0   0 119 254 254 232  75   0   0\n",
      "   0   0   0   0   0   0   0 158 254 254 117   0   0   0   0   0   0   0\n",
      "   0   0   0 118 253 253 154   0   0   0   0   0   0   0   0   0   0 156\n",
      " 253 253 116   0   0   0   0   0   0   0   0   0   0 118 253 253 154   0\n",
      "   0   0   0   0   0   0   0   0   0 156 253 253 116   0   0   0   0   0\n",
      "   0   0   0   0  46 222 253 253 154   0   0   0   0   0   0   0   0   7\n",
      " 116 246 253 180   9   0   0   0   0   0   0   0   0   0   0 118 253 253\n",
      " 154   0   0   0   0   0   0   0   0 116 253 253 253 174   0   0   0   0\n",
      "   0   0   0   0   0   0   0 118 253 253 154   0   0   0   0   0   0   0\n",
      " 110 246 253 253 240  67   0   0   0   0   0   0   0   0   0   0   0 118\n",
      " 253 253 238 215  49  20  20  20  66 215 241 253 245 233  64   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  82 229 253 253 253 253 253 253 253\n",
      " 254 253 253 240 107   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 176 253 253 253 253 253 253 253 254 253 253 108   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  40 239 253 253 253 253\n",
      " 253 253 254 161  57   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "As image:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADdZJREFUeJzt3XGsVOWZx/Hfs2xRYzFCGIFY3ItoqsZYWkds4mZD09hYQsSalJQ/CJsQqAJJSUgoYkxNdCNutu2q2ZDcFiw3KZYSpGBibNU0YnGDXo2iLLuL0duWcrkMES/yj0R5+sc9NLd4551h5pw5c32+n4TMzHnOmfPk6O+emXnPzGvuLgDx/EPZDQAoB+EHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDUP3ZyZ1OnTvWenp5O7hIIZWBgQCdOnLBm1m0r/GZ2h6THJE2Q9HN335hav6enR/39/e3sEkBCtVptet2WX/ab2QRJ/yXp25JukLTYzG5o9fkAdFY77/nnSnrX3d9z9zOSfiVpYT5tAShaO+G/UtKfRz0+ki37O2a2wsz6zay/Vqu1sTsAeWon/GN9qPCZ7we7e6+7V929WqlU2tgdgDy1E/4jkmaOevwlSUfbawdAp7QT/tckXWtms8xsoqTvSdqTT1sAitbyUJ+7f2JmqyX9ViNDfVvc/WBunQEoVFvj/O7+rKRnc+oFQAdxeS8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBtTVLr5kNSPpI0qeSPnH3ah5NoXMOHDiQrO/bty9ZX7lyZZ7t5Oryyy+vW3vllVeS215//fV5t9N12gp/5hvufiKH5wHQQbzsB4JqN/wu6Xdm9rqZrcijIQCd0e7L/tvc/aiZXSHpeTP7X3ffO3qF7I/CCkm66qqr2twdgLy0deZ396PZ7XFJuyTNHWOdXnevunu1Uqm0szsAOWo5/GZ2qZlNOndf0rckvZNXYwCK1c7L/mmSdpnZuefZ5u7P5dIVgMK1HH53f0/SV3LsBS06fPhw3dquXbuS227atClZHxgYSNazP/5daXh4uG5t0aJFyW03b96crM+d+5l3uOMOQ31AUIQfCIrwA0ERfiAowg8ERfiBoPL4Vh8KdurUqWR9yZIldWuvvvpq3u18Lhw8eDBZ37t3b7LOUB+AcYvwA0ERfiAowg8ERfiBoAg/EBThB4JinL8DPvzww2R9zZo1yfozzzyTrJ88efKCe+oGF110UbI+efLkZP3YsWN5thMOZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/g7YuXNnst7X19ehTrrLrFmzkvW1a9cm68uXL8+znXA48wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUA3H+c1si6QFko67+43ZsimStkvqkTQgaZG7j88vledgcHAwWd+6dWuHOrlw999/f7J+9dVXJ+vPPfdcsr5jx466tfvuuy+57ZkzZ5J1tKeZM/8vJN1x3rL1kl5092slvZg9BjCONAy/u++V9MF5ixdKOnc62yrprpz7AlCwVt/zT3P3QUnKbq/IryUAnVD4B35mtsLM+s2sv1arFb07AE1qNfxDZjZDkrLb4/VWdPded6+6e7VSqbS4OwB5azX8eyQtze4vlbQ7n3YAdErD8JvZU5L+W9KXzeyImS2TtFHS7WZ2WNLt2WMA40jDcX53X1yn9M2cexm35s+fn6y/9dZbbT3/hAkTkvUpU6bUra1cuTK57bp165L1Sy65JFlfuHBhsv7QQw/Vrc2ePTu57enTp5P1RtcYNPodhei4wg8IivADQRF+ICjCDwRF+IGgCD8QFD/d3aT9+/fXrb3//vuF7js1lCdJQ0NDhe4/pVFvjeopjaY2Hx4ebvm5wZkfCIvwA0ERfiAowg8ERfiBoAg/EBThB4JinL9JjzzySN3aqVOnCt13o6/lfl698MILbdWRxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8LNJomu9HPawOt4MwPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1HOc3sy2SFkg67u43ZsselLRcUi1bbYO7P1tUk53w6KOPJuu7d+9u+bmnTZuWrN96663JeqNpsj+vli1blqzv27cvWX/yySdb3re7t7zteNHMmf8Xku4YY/lP3X1O9m9cBx+IqGH43X2vpA860AuADmrnPf9qMztgZlvMbHJuHQHoiFbDv0nSbElzJA1K+nG9Fc1shZn1m1l/rVartxqADmsp/O4+5O6fuvtZST+TNDexbq+7V929WqlUWu0TQM5aCr+ZzRj18DuS3smnHQCd0sxQ31OS5kmaamZHJP1I0jwzmyPJJQ1I+n6BPQIoQMPwu/viMRZvLqCXUplZW/WUO++8M1lfsGBBy88dWZH/zdrZdrzgCj8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQYaboPnDgQLK+adOmDnWCcz7++ONk/YknnkjWt23b1vK+58+fn6yvWrWq5eceLzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQYcb5b7rppmT93nvvTdbXr1+fZztQ43H8devWFbbviRMnJusRpkXnzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTUc5zezmZL6JE2XdFZSr7s/ZmZTJG2X1CNpQNIidz9ZXKsYjx5//PG6tQceeKDQfV922WV1axG+r99IM2f+TyStdffrJX1d0iozu0HSekkvuvu1kl7MHgMYJxqG390H3f2N7P5Hkg5JulLSQklbs9W2SrqrqCYB5O+C3vObWY+kr0raL2mauw9KI38gJF2Rd3MAitN0+M3si5J2Slrj7qcuYLsVZtZvZv21Wq2VHgEUoKnwm9kXNBL8X7r709niITObkdVnSDo+1rbu3uvuVXevViqVPHoGkIOG4Tczk7RZ0iF3/8mo0h5JS7P7SyXtzr89AEVp5iu9t0laIultM3szW7ZB0kZJvzazZZL+JOm7xbQ4/u3YsSNZf/nll5P1Rj9RPXPmzAvuqVmNfvK80ZDZ0aNH69Ya/XT3xRdfnKxPmjQpWd++fXvd2rx585LbRtAw/O7+B0lWp/zNfNsB0Clc4QcERfiBoAg/EBThB4Ii/EBQhB8IKsxPdzdyzTXXJOvTp0+vWzt27Fhy2+Hh4bbqN998c7JeJHdP1keuAWtN6iu3kvTwww8n66tXr2553+DMD4RF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc6fufvuu5P1vr6+urU9e/bk3U4IjOOXizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH+TNm7cWLf20ksvJbdt9H398WzJkiXJ+j333FO3dsstt+TdDi4AZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrhOL+ZzZTUJ2m6pLOSet39MTN7UNJySbVs1Q3u/mxRjZbtuuuuq1s7efJkBzsB8tHMRT6fSFrr7m+Y2SRJr5vZ81ntp+7+H8W1B6AoDcPv7oOSBrP7H5nZIUlXFt0YgGJd0Ht+M+uR9FVJ+7NFq83sgJltMbPJdbZZYWb9ZtZfq9XGWgVACZoOv5l9UdJOSWvc/ZSkTZJmS5qjkVcGPx5rO3fvdfequ1crlUoOLQPIQ1PhN7MvaCT4v3T3pyXJ3Yfc/VN3PyvpZ5LmFtcmgLw1DL+NTMO6WdIhd//JqOUzRq32HUnv5N8egKI082n/bZKWSHrbzN7Mlm2QtNjM5khySQOSvl9IhwAK0cyn/X+QNNYk7J/bMX0gAq7wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBGXu3rmdmdUk/XHUoqmSTnSsgQvTrb11a18SvbUqz97+yd2b+r28job/Mzs363f3amkNJHRrb93al0RvrSqrN172A0ERfiCossPfW/L+U7q1t27tS6K3VpXSW6nv+QGUp+wzP4CSlBJ+M7vDzP7PzN41s/Vl9FCPmQ2Y2dtm9qaZ9ZfcyxYzO25m74xaNsXMnjezw9ntmNOkldTbg2b2l+zYvWlm80vqbaaZ/d7MDpnZQTP7Qba81GOX6KuU49bxl/1mNkHS/0u6XdIRSa9JWuzu/9PRRuowswFJVXcvfUzYzP5F0mlJfe5+Y7bs3yV94O4bsz+ck939h13S24OSTpc9c3M2ocyM0TNLS7pL0r+qxGOX6GuRSjhuZZz550p6193fc/czkn4laWEJfXQ9d98r6YPzFi+UtDW7v1Uj//N0XJ3euoK7D7r7G9n9jySdm1m61GOX6KsUZYT/Skl/HvX4iLprym+X9Dsze93MVpTdzBimZdOmn5s+/YqS+zlfw5mbO+m8maW75ti1MuN13soI/1iz/3TTkMNt7v41Sd+WtCp7eYvmNDVzc6eMMbN0V2h1xuu8lRH+I5Jmjnr8JUlHS+hjTO5+NLs9LmmXum/24aFzk6Rmt8dL7udvumnm5rFmllYXHLtumvG6jPC/JulaM5tlZhMlfU/SnhL6+AwzuzT7IEZmdqmkb6n7Zh/eI2lpdn+ppN0l9vJ3umXm5nozS6vkY9dtM16XcpFPNpTxn5ImSNri7v/W8SbGYGZXa+RsL41MYrqtzN7M7ClJ8zTyra8hST+S9BtJv5Z0laQ/Sfquu3f8g7c6vc3TyEvXv83cfO49dod7+2dJL0t6W9LZbPEGjby/Lu3YJfparBKOG1f4AUFxhR8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaD+CkN86EIvFHDUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "index = 4\n",
    "print(\"Value of datapoint no. {}:\\n{}\\n\".format(index,mnist_data[index]))\n",
    "print(\"As image:\\n\")\n",
    "plt.imshow(mnist_data[index].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Split the MNIST dataset into a training set and a test set. Use 60,000 instances for training and 10,000 for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Train a Random Forest classifier on the dataset and time how long it takes.\n",
    "   Then evaluate the resulting model on the test set (disregarding \"don't use test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Train a new Random Forest classifier on the reduced dataset and see how long it takes.\n",
    "   Was training much faster? Next evaluate the classifier on the test set: how does it\n",
    "   compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Using at least two other classifiers from the curriculum, train a model on the reduced dataset. For each model, you must tune at least two hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Use t_SNE to reduce the MNIST dataset down to two dimensions and plot the result using\n",
    "   Matplotlib. You can use a scatterplot using 10 different colors to represent each image’s\n",
    "   target class. Alternatively, you can write colored digits at the location of each instance,\n",
    "   or even plot scaled-down versions of the digit images themselves.\n",
    "   You should get a nice visualization with well-separated clusters of digits.\n",
    "   Do the same using PCA and compare the resulting vizualisations. You can see examples in the course book pp. 168-169."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** These questions require no code.\n",
    " - What are the main motivations for reducing a dataset’s dimensionality? What are the main drawbacks?\n",
    "\n",
    " - Once a dataset’s dimensionality has been reduced, is it possible to reverse the operation? If so, how? If not, why?\n",
    "\n",
    " - Can PCA be used to reduce the dimensionality of a highly nonlinear dataset? Explain.\n",
    "\n",
    " - Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained variance ratio to 95%. How many dimensions will the resulting dataset have?\n",
    "\n",
    " - How can you evaluate the performance of a dimensionality reduction algorithm on your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we return to the MNIST data, and we are exploring several clustering techniques with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Perform k-means clustering with k=10 on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Using visualization techniques analogous to what we have done in the Clustering notebook\n",
    "   for the faces data, can you determine the 'nature' of the 10 constructed clusters?\n",
    "   Do the clusters (roughly) coincide with the 10 different actual digits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Perform a supervised clustering evaluation using adjusted rand index.\n",
    "   Are the results stable, when you perform several random restarts of k-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Now perform hierarchical clustering on the data.\n",
    "   (in order to improve visibility in the constructed dendrograms, you can also use a\n",
    "   much reduced dataset as constructed using sklearn.utils.resample shown below).\n",
    "   Does the visual analysis of the dendrogram indicate a natural number of clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** Using different cluster distance metrics (ward,single,average, etc.),\n",
    "   what do the clusterings look like that are produced at the level of k=10 clusters?\n",
    "   See the Clustering notebook for the needed Python code, including the fcluster\n",
    "   method to retrieve 'plain' clusterings from the hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mnist_data,small_mnist_label = skl.utils.resample(mnist.data,mnist.target,n_samples=200,replace='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Do a DBSCAN clustering of the small dataset. Tweak the different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g)** Try to compare the different clustering methods on the MNIST dataset in the same way\n",
    "   the book does on the faces dataset on pp. 195-206."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
